{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "0863265a-f992-4423-a41d-39cea15301f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-07 12:54:17--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.184.100, 64.233.184.101, 64.233.184.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.184.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/otcfkdrk63mfva9smgeol90s79upkh7n/1651928025000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-07 12:54:20--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/otcfkdrk63mfva9smgeol90s79upkh7n/1651928025000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 173.194.76.132, 2a00:1450:400c:c00::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|173.194.76.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   119MB/s    in 0.6s    \n",
            "\n",
            "2022-05-07 12:54:21 (119 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "outputId": "63e6c729-099d-4b24-d196-1e1033915fe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "outputId": "482d1abe-dcf8-4ac2-9b51-95a7c51c36c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 33s 14ms/step - loss: 5.9795 - accuracy: 0.0465\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 5.6803 - accuracy: 0.0494\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 5.4963 - accuracy: 0.0630\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.3526 - accuracy: 0.0789\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 5.2130 - accuracy: 0.1029\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.0676 - accuracy: 0.1249\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.9332 - accuracy: 0.1375\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.8109 - accuracy: 0.1472\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.6974 - accuracy: 0.1575\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.5898 - accuracy: 0.1691\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.4753 - accuracy: 0.1782\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.3659 - accuracy: 0.1922\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.2611 - accuracy: 0.2022\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.1834 - accuracy: 0.2107\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.1189 - accuracy: 0.2212\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 4.0383 - accuracy: 0.2331\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.9651 - accuracy: 0.2416\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.9076 - accuracy: 0.2480\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.8519 - accuracy: 0.2584\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.7986 - accuracy: 0.2627\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.7483 - accuracy: 0.2690\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.6989 - accuracy: 0.2764\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.6532 - accuracy: 0.2825\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.6213 - accuracy: 0.2859\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.5700 - accuracy: 0.2938\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.5357 - accuracy: 0.2984\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.4921 - accuracy: 0.3058\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.4538 - accuracy: 0.3096\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.4184 - accuracy: 0.3160\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.3877 - accuracy: 0.3185\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.3540 - accuracy: 0.3252\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.3195 - accuracy: 0.3308\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.2894 - accuracy: 0.3345\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.2582 - accuracy: 0.3401\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.2291 - accuracy: 0.3444\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.2000 - accuracy: 0.3481\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.1705 - accuracy: 0.3527\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.1502 - accuracy: 0.3562\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.1218 - accuracy: 0.3601\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.0956 - accuracy: 0.3645\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.0765 - accuracy: 0.3664\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.0511 - accuracy: 0.3715\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.0283 - accuracy: 0.3755\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 3.0111 - accuracy: 0.3784\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9930 - accuracy: 0.3802\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9729 - accuracy: 0.3837\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9517 - accuracy: 0.3872\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9337 - accuracy: 0.3907\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9201 - accuracy: 0.3921\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.9101 - accuracy: 0.3934\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.8827 - accuracy: 0.3979\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.8630 - accuracy: 0.4004\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.8495 - accuracy: 0.4042\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.8372 - accuracy: 0.4058\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.8259 - accuracy: 0.4078\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7982 - accuracy: 0.4139\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7835 - accuracy: 0.4157\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7718 - accuracy: 0.4189\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7617 - accuracy: 0.4211\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7447 - accuracy: 0.4238\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7292 - accuracy: 0.4256\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7125 - accuracy: 0.4291\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.7096 - accuracy: 0.4307\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6951 - accuracy: 0.4312\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6813 - accuracy: 0.4346\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6678 - accuracy: 0.4369\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6563 - accuracy: 0.4394\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6469 - accuracy: 0.4411\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6292 - accuracy: 0.4448\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6248 - accuracy: 0.4436\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6068 - accuracy: 0.4475\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5961 - accuracy: 0.4488\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5936 - accuracy: 0.4502\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5762 - accuracy: 0.4531\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5635 - accuracy: 0.4549\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5577 - accuracy: 0.4556\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5578 - accuracy: 0.4549\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5440 - accuracy: 0.4590\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5445 - accuracy: 0.4572\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5252 - accuracy: 0.4636\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5084 - accuracy: 0.4640\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5009 - accuracy: 0.4657\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5032 - accuracy: 0.4674\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4795 - accuracy: 0.4713\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4746 - accuracy: 0.4716\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4715 - accuracy: 0.4713\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4615 - accuracy: 0.4726\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4551 - accuracy: 0.4753\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4394 - accuracy: 0.4775\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4489 - accuracy: 0.4748\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4320 - accuracy: 0.4797\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4109 - accuracy: 0.4830\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4102 - accuracy: 0.4814\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4159 - accuracy: 0.4815\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3915 - accuracy: 0.4876\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3838 - accuracy: 0.4881\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3742 - accuracy: 0.4904\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3753 - accuracy: 0.4876\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3733 - accuracy: 0.4892\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.3591 - accuracy: 0.4920\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "outputId": "29ac33fe-ee2c-4416-be82-e920edc29cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "outputId": "dc90ec0c-f65e-4a52-fbfc-dc1626cac178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im feeling chills fun and it seems to blame to me and make me so hard to do it all here day we can jive having the other day comin like and i kissed the other jet black flu of beyond falling dull rides rides everythings rides rides everythings rides rides stayed treat realize las tells bell depressed chuck bless mr dying into healing moods bends now its going to me and get everyday babe by their inside the world inside day we play the floor up to the office yeah wont the little heart that shove on me on fire gently of\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "outputId": "47fadbcc-ca1b-4fd0-ece9-cab81983ab1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "outputId": "49091cdf-1af2-4dd8-a097-542cfc56359d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im feeling chills love of sweet mama said yes i i think it own ahha ahha ahha ahha ahha ahha ahha is no more shy shame care no kisses track give last prolonged goodbye meets in space rides lordy gone two guys that plans two rides rides everythings ago everythings night seventeen goodnight needs jump back figure for ive been pride fire going music fly can seem learned life to be so hard awhile to the wild rides rides ohalalala surrender waited heart and let the in side rocking would take darling hard lovelight lots to be that of dead glow and i\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}